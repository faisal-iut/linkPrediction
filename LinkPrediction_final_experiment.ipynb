{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import graph as gr\n",
    "import utils as ut\n",
    "import feature_selection as fs\n",
    "import classification as cl\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "import community\n",
    "import seaborn as sns\n",
    "from gensim.models import KeyedVectors\n",
    "from pyemd import emd\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.matutils import softcossim\n",
    "import copy\n",
    "import itertools\n",
    "import pickle\n",
    "import PathSim as ps\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########dataset and domain selection : sleep apnea: 0 ; obesity:1\n",
    "importlib.reload(ut)\n",
    "select_domain  = 0   ###[set 0 for apnea, 1 for obesity]\n",
    "domain = ['apnea','obesity']\n",
    "root = '../linkPrediction/'\n",
    "filepath=[['dataset/apnea-all,3.csv',\n",
    "         'dataset/apnea-distinct_keyword.csv'],\n",
    "        ['dataset/obesity-all,3.csv',\n",
    "         'dataset/obesity-distinct_keyword.csv']]\n",
    "########path to save graph files\n",
    "graphpath=root+'graphs/'+domain[select_domain]\n",
    "########path to save result files, data files and resultent figures\n",
    "datapath=root+'dataframes/'+domain[select_domain]\n",
    "#path to save classification models\n",
    "modelpath=root+'models/'+domain[select_domain]\n",
    "########columns with sub-columns\n",
    "column_split=['keyword','author_name','affiliation_1','affiliation_2','country']\n",
    "#time=[parent_year, train:start_year, test:start_year, no_of_test_years(1), total_year_in_each_iteration, no of grandparents]\n",
    "time=[2007,2008,2015,1,1,20]\n",
    "times=time\n",
    "######load dataset and keyword list into dataframes\n",
    "df, key_list = ut.load_dataset(filepath[select_domain], column_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######graph building and saving in graphpath: train graph, test graph and parent graph(previous year of train graph)  \n",
    "importlib.reload(gr)\n",
    "time=[2007,2008,2015,1,1,20]\n",
    "gr.dynamic_train_test_graph_build(df, key_list, graphpath, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/graphs/apnea\\train_graph_2008.gpickle loaded, nodes: 459 edges: 773\n",
      "../linkPrediction/graphs/apnea\\train_graph_2009.gpickle loaded, nodes: 470 edges: 688\n",
      "../linkPrediction/graphs/apnea\\train_graph_2010.gpickle loaded, nodes: 496 edges: 786\n",
      "../linkPrediction/graphs/apnea\\train_graph_2011.gpickle loaded, nodes: 536 edges: 977\n",
      "../linkPrediction/graphs/apnea\\train_graph_2012.gpickle loaded, nodes: 584 edges: 1054\n",
      "../linkPrediction/graphs/apnea\\train_graph_2013.gpickle loaded, nodes: 634 edges: 1280\n",
      "../linkPrediction/graphs/apnea\\train_graph_2014.gpickle loaded, nodes: 583 edges: 1144\n",
      "../linkPrediction/graphs/apnea\\test_graph_2015.gpickle loaded, nodes: 1093 edges: 2019\n",
      "../linkPrediction/graphs/apnea\\parent_graph_2007-2008.gpickle loaded, nodes: 388 edges: 689\n",
      "../linkPrediction/graphs/apnea\\train_graph_2008-2015.gpickle loaded, nodes: 1093 edges: 5142\n",
      "../linkPrediction/graphs/apnea\\test_graph_2015-2016.gpickle loaded, nodes: 1093 edges: 2019\n"
     ]
    }
   ],
   "source": [
    "# time=[1991,1992,1994,1,1,20]\n",
    "importlib.reload(gr)\n",
    "g_train, g_test, g_parent, g_train_static, g_test_static = gr.graph_load(graphpath, time)\n",
    "# g_train, g_test = gr.graph_norm(root, domain, select_domain, g_train, g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_key={0:[9875,1020],1:[7614,9953]}\n",
    "for t in range(2008,2015):\n",
    "    g_train[t].remove_nodes_from(s_key[select_domain])\n",
    "g_test[2015].remove_nodes_from(s_key[select_domain])\n",
    "g_parent.remove_nodes_from(s_key[select_domain])\n",
    "g_train_static.remove_nodes_from(s_key[select_domain])\n",
    "g_test_static.remove_nodes_from(s_key[select_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fs)\n",
    "importlib.reload(cl)\n",
    "#ration of negative:positive train instance:(eg,10 for 10:1=neg:pos)\n",
    "freq=10\n",
    "##### time=[2001,2007,2015,1,1,10]\n",
    "##### train_data building: dictionary of each years non-connected node pairs dataframes\n",
    "train_data, train_data_static, parent_data, test_data_static, edge_list = cl.non_edge_feature_dataframe(g_train, \n",
    "                                                                                                         g_test,\n",
    "                                                                                                         g_parent,\n",
    "                                                                                                         g_train_static, \n",
    "                                                                                                         g_test_static,  \n",
    "                                                                                                         time, \n",
    "                                                                                                         freq)\n",
    "#### train_data: non-connected node pairs with feature values\n",
    "####node_features: node feature values\n",
    "node_feature, train_data = fs.dynamic_graph_feature_set(df, key_list, train_data, g_parent, g_train, g_train_static, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save train data (edge data and node data) and edge list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importlib.reload(ut)\n",
    "ut.save_data(train_data, datapath, domain[select_domain], \"train_data\", time)\n",
    "ut.save_data(node_feature, datapath, domain[select_domain], \"node_feature\", time)\n",
    "ut.save_data(edge_list, datapath, domain[select_domain], \"edge_list\", time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(fs)\n",
    "importlib.reload(cl)\n",
    "\n",
    "edge_list = ut.load_data(datapath, domain[select_domain], \"edge_list\", time)\n",
    "edge_set = set(edge_list)\n",
    "edges = list(g_test[2015].edges())\n",
    "non_edges =  list(nx.non_edges(g_test[2015]))\n",
    "r_edges = [(b, a) for a, b in edges]\n",
    "r_non_edges = [(b, a) for a, b in non_edges]\n",
    "test_edges = []\n",
    "label = []\n",
    "train_ed=[]\n",
    "ins = set(edges).intersection(edge_set)\n",
    "train_ed.extend(ins)\n",
    "label.extend([1]*len(ins))\n",
    "ins = set(r_edges).intersection(edge_set)\n",
    "train_ed.extend(ins)\n",
    "label.extend([1]*len(ins))\n",
    "ins = set(non_edges).intersection(edge_set)\n",
    "train_ed.extend(ins)\n",
    "label.extend([0]*len(ins))\n",
    "ins = set(r_non_edges).intersection(edge_set)\n",
    "train_ed.extend(ins)\n",
    "label.extend([0]*len(ins))\n",
    "train_data={}\n",
    "train_data[2015] = pd.DataFrame({'row_name': train_ed, 'label': label})\n",
    "\n",
    "g_train[2015]=g_test[2015]\n",
    "time=[2014,2015,2016,1,1,20]\n",
    "test_node, test_data = fs.dynamic_graph_feature_set(df, key_list, train_data, g_train[2014], g_train, g_train_static, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save test data (edge data and node data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ut)\n",
    "time=[2007,2008,2015,1,1,20]\n",
    "ut.save_data(test_data, datapath, domain[select_domain], \"test_data\", time)\n",
    "ut.save_data(test_node, datapath, domain[select_domain], \"test_node\", time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train, test and edge data from saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "train data length: 7\n",
      "node feature length: 7\n",
      "edge_list length: 12494\n",
      "test_data length: 12494\n",
      "test_node length: 1093\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ut)\n",
    "train_data = ut.load_data(datapath, domain[select_domain], \"train_data\", times)\n",
    "node_feature = ut.load_data(datapath, domain[select_domain], \"node_feature\", times)\n",
    "edge_list = ut.load_data(datapath, domain[select_domain], \"edge_list\", times)\n",
    "test_data = ut.load_data(datapath, domain[select_domain], \"test_data\", times)\n",
    "test_node = ut.load_data(datapath, domain[select_domain], \"test_node\", times)\n",
    "print('train data length:',len(train_data))\n",
    "print('node feature length:',len(node_feature))\n",
    "print('edge_list length:',len(edge_list))\n",
    "print('test_data length:',len(test_data[2015]))\n",
    "print('test_node length:',len(test_node[2015]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature data reshape function to transform dataframes for LSTM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(train_data, node_feature, edge_list, test_data,test_node,times,features):\n",
    "    cat ={25:0,5:1,3:2,1:3} ####predefined geneoligical heredity score (eg. 25 for grandparent, 5 for parent)\n",
    "    ts = times[1]\n",
    "    te = times[2]+1\n",
    "    it_index = times[4]\n",
    "    times_range = te - ts\n",
    "    total_sample = len(edge_list)\n",
    "    train_data[times[2]] = test_data\n",
    "    node_feature[times[2]] = test_node\n",
    "    feature_length = len(features['edge'])+32\n",
    "    X = np.zeros([total_sample, times_range, feature_length])\n",
    "    y = np.zeros(total_sample)\n",
    "    print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "    for id, edge in enumerate(edge_list):\n",
    "        for t in range(ts, te, it_index):\n",
    "            t_data = train_data[t]\n",
    "            n_data = node_feature[t]\n",
    "            node_list = set(n_data['node_index'])\n",
    "            edge_list_t = set(t_data['row_name'])\n",
    "            if edge in edge_list_t:\n",
    "                train_row = np.asarray(t_data.loc[t_data['row_name'] == edge,features['edge']].values[0])\n",
    "                X[id][t - ts][0:6] = train_row\n",
    "                X[id][t - ts][3] = X[id][t - ts][3]*(t-ts+1)*2\n",
    "            if edge[0] in node_list:\n",
    "                node_row0 = np.asarray(n_data.loc[n_data['node_index'] == edge[0],features['node']].values[0])\n",
    "                X[id][t - ts][6:9] = node_row0[0:3]\n",
    "                X[id][t - ts][cat[node_row0[3]]+9] = 1\n",
    "                X[id][t - ts][cat[node_row0[4]]+13] = 1\n",
    "                X[id][t - ts][cat[node_row0[5]]+17] = 1\n",
    "                X[id][t - ts][21] = node_row0[6]\n",
    "                if edge[1] not in node_list:\n",
    "                    X[id][t - ts][3] = node_row0[6]*(t-ts+1)\n",
    "            if edge[1] in node_list:\n",
    "                node_row1 = np.asarray(n_data.loc[n_data['node_index'] == edge[1],features['node']].values[0])\n",
    "                X[id][t - ts][22:25] = node_row1[0:3]\n",
    "                X[id][t - ts][cat[node_row1[3]]+25] = 1\n",
    "                X[id][t - ts][cat[node_row1[4]]+29] = 1\n",
    "                X[id][t - ts][cat[node_row1[5]]+33] = 1\n",
    "                X[id][t - ts][37] = node_row1[6]\n",
    "                if edge[0] not in node_list:\n",
    "                    X[id][t - ts][3] = node_row1[6]*(t-ts+1)\n",
    "        y[id] = test_data.loc[test_data['row_name'] == edge,'label'].values[0]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### node and edge feature catagories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [{'node':['term_aut','node_type_aut'],\n",
    "           'edge':['typeaut']},\n",
    "           {'node':['term_art','node_type_art'],\n",
    "           'edge':['typeart']},\n",
    "           {'node':['degree','node_type_deg'],\n",
    "           'edge':['typenode']},\n",
    "           {'node':['citation'],\n",
    "           'edge':['citation1']},\n",
    "           {'node':['degree'],\n",
    "           'edge':['pref']},\n",
    "           {'node':['degree'],\n",
    "           'edge':['cm']}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping dataframe and putting features into the specific column index location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################  6           7        8       9,10,11,12     13,14,15,16      17,18,19,20      21\n",
    "#####################  22          23       24      25,26,27,28    29,30,31,32      33,34,35,36      37\n",
    "feature = {'node':['term_aut','term_art','degree','node_type_aut','node_type_art','node_type_deg','citation'],\n",
    "           'edge':['typeaut','typeart','typenode','citation1','pref','cm']}\n",
    "################       0         1         2           3        4      5\n",
    "\n",
    "start = tm.time()\n",
    "X, y = reshape(train_data, node_feature, edge_list, test_data[2015],test_node[2015],times,feature)\n",
    "end = tm.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving reshaped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.save_data(X, datapath, domain[select_domain], \"X-features\", times)\n",
    "ut.save_data(y, datapath, domain[select_domain], \"y-features\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column index for each feature type in reshaped X feature array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions for LSTM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class CustomSaver(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, param):\n",
    "        self.name = param[3]\n",
    "        self.times = param[4]\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        ep_set =set([100,500,1000])\n",
    "        if epoch in ep_set:  # or save after some epoch, each k-th epoch etc.\n",
    "            ut.save_data(self.model, datapath, domain[select_domain], \"model-\"+name+\"-\"+str(epoch), self.times)\n",
    "\n",
    "def create_linear(param):\n",
    "        inputx = Input(shape=(param[0], param[1]))\n",
    "        x = LSTM(20)(inputx)\n",
    "        x = LSTM(20, activation=\"relu\")(inputx)\n",
    "        x = Dense(40, activation=\"relu\")(x)\n",
    "        x = Dense(20, activation=\"relu\")(x)\n",
    "        x = Dense(param[2],activation='linear',name=\"lin\")(x)\n",
    "        model = Model(inputs=inputx, outputs=x)\n",
    "        return model\n",
    "\n",
    "def create_cat1(param):\n",
    "        inputx = Input(shape=(param[0], param[1]))\n",
    "        x = LSTM(20)(inputx)\n",
    "        x = Dense(20)(x)\n",
    "        x = Dense(10,activation='relu')(x)\n",
    "        x = Dense(param[2],activation='softmax',name=\"cat1\")(x)\n",
    "        model = Model(inputs=inputx, outputs=x)\n",
    "        return model\n",
    "    \n",
    "def create_cat2(param):\n",
    "        inputx = Input(shape=(param[0], param[1]))\n",
    "        x = LSTM(20)(inputx)\n",
    "        x = Dense(20)(x)\n",
    "        x = Dense(10,activation='relu')(x)\n",
    "        x = Dense(param[2],activation='softmax',name=\"cat2\")(x)\n",
    "        model = Model(inputs=inputx, outputs=x)\n",
    "        return model\n",
    "    \n",
    "def lstm_forecast(X,param):\n",
    "        X = ut.scale(X,0,1)\n",
    "        y = X[:,7]\n",
    "        X = X[:,0:7]\n",
    "        batch_size = param[1]\n",
    "        epoch = param[2]\n",
    "        names1 = set(['author','article','degree'])\n",
    "        names2 = set(['citation','pref','cm'])\n",
    "        print(X.shape,y.shape)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = param[0], random_state = 0)\n",
    "        ######## the first branch operates on the linear input\n",
    "\n",
    "        lin_parameters = [X_train[:,:,0:3].shape[1], X_train[:,:,0:3].shape[2], y_train[:,0:3].shape[1]]\n",
    "        lin = create_linear(lin_parameters)        \n",
    "        \n",
    "        saver = CustomSaver(param)\n",
    "        \n",
    "        if param[3] in names1:\n",
    "            cat_parameters1 = [X_train[:,:,3:7].shape[1], X_train[:,:,3:7].shape[2], y_train[:,3:7].shape[1]]\n",
    "            cat1 = create_cat1(cat_parameters1)\n",
    "\n",
    "            cat_parameters2 = [X_train[:,:,7:11].shape[1], X_train[:,:,7:11].shape[2], y_train[:,7:11].shape[1]]\n",
    "            cat2 = create_cat2(cat_parameters2)\n",
    "        \n",
    "            model = Model(inputs=[lin.input, cat1.input, cat2.input], outputs=[lin.output, cat1.output,cat2.output])\n",
    "            model.compile(loss={'lin':'mse','cat1':'categorical_crossentropy','cat2':'categorical_crossentropy'},\n",
    "                              optimizer='Adam',\n",
    "                              metrics={'lin':'accuracy','cat1':'categorical_accuracy','cat2':'categorical_accuracy'})\n",
    "            history = model.fit([X_train[:,:,0:3],X_train[:,:,3:7],X_train[:,:,7:11]],\n",
    "                                [y_train[:,0:3],y_train[:,3:7],y_train[:,7:11]],\n",
    "                                callbacks=[saver],\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epoch,\n",
    "                                verbose=1)\n",
    "        else:\n",
    "            model = Model(inputs=lin.input, outputs=lin.output)\n",
    "            model.compile(loss={'lin':'mse'},\n",
    "                              optimizer='Adam',\n",
    "                              metrics={'lin':'accuracy'})\n",
    "            history = model.fit(X_train[:,:,0:3],\n",
    "                                y_train[:,0:3],\n",
    "                                callbacks=[saver],\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epoch,\n",
    "                                verbose=1)\n",
    "#         y_pr = model.predict([X_test[:,:,0:3],X_test[:,:,3:7],X_test[:,:,7:11]])\n",
    "        return X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries forecasting Training and saving to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = {\n",
    "# 'author':[0,6,22,9,10,11,12,25,26,27,28]\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32]\n",
    "# 'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "# 'citation': [3,21,37],\n",
    "# 'pref': [4,8,24],\n",
    "# 'cm': [5,8,24]\n",
    "}\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "X = ut.load_data(datapath, domain[select_domain], \"X-features\", times)\n",
    "y = ut.load_data(datapath, domain[select_domain], \"y-features\", times)\n",
    "for name,feature in feature_names.items():\n",
    "    ### running for only first 3 features\n",
    "    if name in names1:\n",
    "        param = [0.3,64,1001,name,times]\n",
    "        print(name,\"---------------------------------------------------------------------------------\")\n",
    "        X_test, y_test = lstm_forecast(X[:,:,feature],param)\n",
    "        ut.save_data(X_test, datapath, domain[select_domain], \"X_test-\"+name, times)\n",
    "        ut.save_data(y_test, datapath, domain[select_domain], \"y_test-\"+name, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing RMSE values for the forecasted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obesity =1, apnea =0 [select_domain=0 or 1]\n",
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "epochs = [100,500,1000]\n",
    "for name,feature in feature_names.items():\n",
    "    X_test = ut.load_data(datapath, domain[select_domain], \"X_test-\"+name, times)\n",
    "    y_test = ut.load_data(datapath, domain[select_domain], \"y_test-\"+name, times)\n",
    "    for ep in epochs:      \n",
    "        if name in names1:\n",
    "            m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(ep), times)    \n",
    "            y_pr = m.predict([X_test[:,:,0:3],X_test[:,:,3:7],X_test[:,:,7:11]])\n",
    "            mse = mean_squared_error(y_test[:,0],y_pr[0][:,0])\n",
    "            rmse1 = sqrt(mse)\n",
    "            mse = mean_squared_error(y_test[:,1],y_pr[0][:,1])\n",
    "            rmse2 = sqrt(mse)\n",
    "            print(name,\"-\",ep,\":\",rmse1,\" --- \",rmse2)\n",
    "        if name in names2:\n",
    "            m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(ep), times)\n",
    "            y_pr = m.predict(X_test)\n",
    "            mse = mean_squared_error(y_test[:,0],y_pr[:,0])\n",
    "            rmse1 = sqrt(mse)\n",
    "            mse = mean_squared_error(y_test[:,1],y_pr[:,1])\n",
    "            rmse2 = sqrt(mse)\n",
    "            print(name,\"-\",ep,\":\",rmse1,\" --- \",rmse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function for link classification using the forecasted result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class(param):\n",
    "    inputx = Input(shape=(param[1],))\n",
    "    x = Dense(20, activation='relu')(inputx)\n",
    "    x = Dense(10,activation='relu')(x)\n",
    "    x = Dense(1,activation='sigmoid',name=\"class\")(x)\n",
    "    model = Model(inputs=inputx, outputs=x)\n",
    "    return model\n",
    "\n",
    "def lstm_classification(X,y,param):\n",
    "    batch_size = param[1]\n",
    "    epoch = param[2]\n",
    "    print(X.shape,y.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = param[0], random_state = 0)\n",
    "    class_param = [X.shape[0], X.shape[1], 1]\n",
    "    print(class_param)\n",
    "    \n",
    "    cl = create_class(class_param)\n",
    "    model = Model(inputs=cl.input, outputs=cl.output)\n",
    "    model.compile(loss={'class':'binary_crossentropy'},\n",
    "                      optimizer='Adam',\n",
    "                      metrics={'class':'accuracy'})\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                        shuffle=True,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epoch,\n",
    "                        verbose=1)\n",
    "    return X_test, y_test, model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link classification training and saving into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}\n",
    "\n",
    "results = []\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "X = ut.load_data(datapath, domain[select_domain], \"X-features\", times)\n",
    "y = ut.load_data(datapath, domain[select_domain], \"y-features\", times)\n",
    "for name,feature in feature_names.items():\n",
    "    param = [0.3,64,500,name,times]\n",
    "    m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(1000), times)\n",
    "    X1=X[:,:,feature]\n",
    "    X1=X1[:,0:7]\n",
    "    print(name, X1.shape, \"--------------------------------------------------------------------\")\n",
    "    if name in names1:\n",
    "        y_pr = m.predict([X1[:,:,0:3],X1[:,:,3:7],X1[:,:,7:11]])\n",
    "#         row_maxes = y_pr[1].max(axis=1).reshape(-1, 1)\n",
    "#         y_pr[1][:] = np.where(y_pr[1] == row_maxes, 1, 0)\n",
    "#         row_maxes = y_pr[2].max(axis=1).reshape(-1, 1)\n",
    "#         y_pr[2][:] = np.where(y_pr[2] == row_maxes, 1, 0)\n",
    "        y_pr1 = np.concatenate((y_pr[0],y_pr[1],y_pr[2]),axis=1)\n",
    "    if name in names2:\n",
    "        y_pr1 = m.predict(X1)\n",
    "    X_test, y_test, model = lstm_classification(y_pr1,y,param)\n",
    "    results.append(cl.model_evaluate(model, X_test, y_test, param[1], name))\n",
    "ut.save_data(results, datapath, domain[select_domain], \"results\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading classification result files and printing auc and accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ut.load_data(datapath, domain[select_domain], \"results\", times)\n",
    "for result in results:\n",
    "    print(result['model name'], result['auc'], result['test accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
