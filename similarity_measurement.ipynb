{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import operator as op\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg\n",
    "import cmath\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import scipy.optimize as optimize\n",
    "from tabulate import tabulate\n",
    "from documentCentrality import document_centrality\n",
    "from networkx import algorithms as ag\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_split(df,key):\n",
    "    df[key]= df[key].str.split(\"; \", n = 20, expand = False)  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_key_find(kl,label):\n",
    "    key=kl[kl['keyword']==label]['id'].iloc[0]\n",
    "    return key\n",
    "\n",
    "def node_label_find(kl,key):\n",
    "    label=kl[kl['id']==key]['keyword'].iloc[0]\n",
    "    return label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_intersection(df,kl,t0,t1,t2):\n",
    "    prelist=[]\n",
    "    postlist=[]\n",
    "    pre_df=df[(df['art_year']>=t0)&(df['art_year']<t1)]\n",
    "    post_df=df[(df['art_year']>=t1)&(df['art_year']<t2)]\n",
    "    for index, row in pre_df.iterrows():\n",
    "        for label in row[\"keyword\"]:\n",
    "            node_id=node_key_find(kl,label)\n",
    "            prelist.append(node_id)\n",
    "    for index, row in post_df.iterrows():\n",
    "        for label in row[\"keyword\"]:\n",
    "            node_id=node_key_find(kl,label)\n",
    "            postlist.append(node_id)\n",
    "    return set(prelist).intersection(set(postlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(g,df,kl,nodes,t0,t1):\n",
    "    g_df=df[(df['art_year']>=t0)&(df['art_year']<t1)]\n",
    "    #node insert\n",
    "    for index, row in g_df.iterrows():\n",
    "        for label in row[\"keyword\"]:\n",
    "            node_id=node_key_find(kl,label)\n",
    "            if node_id in nodes:\n",
    "                if g.has_node(node_id):\n",
    "                    g.nodes[node_id]['art_id'].add(row[\"art_id\"])\n",
    "                    g.nodes[node_id]['year'].add(row[\"art_year\"])\n",
    "                    g.nodes[node_id]['title'].add(row[\"title\"])\n",
    "                else:\n",
    "                    art_id={row[\"art_id\"]}\n",
    "                    year={row[\"art_year\"]}\n",
    "                    title={row[\"title\"]}\n",
    "                    g.add_node(node_id,art_id=art_id,year=year,title=title)\n",
    "    #edge insert\n",
    "    for index, row in g_df.iterrows():\n",
    "        edges=list(itertools.combinations(row[\"keyword\"], 2))\n",
    "        for edge in edges:\n",
    "            node1=node_key_find(kl,edge[0])\n",
    "            node2=node_key_find(kl,edge[1])\n",
    "            if (node1 in nodes) and (node2 in nodes) and (node1!=node2):\n",
    "                if not g.has_edge(node1,node2):\n",
    "                    g.add_edge(node1,node2)                \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_and_article_feature(df,kl,g,t0,t1):\n",
    "    f_df=df[(df['art_year']>=t0)&(df['art_year']<t1)]\n",
    "    article_set=[]\n",
    "    node_set=[]\n",
    "    for nd,art in g.node(data='art_id'):\n",
    "        node_set.append(nd)\n",
    "        for art_s in art:\n",
    "            article_set.append(art_s)\n",
    "    article_set= set(article_set)\n",
    "    print(len(article_set))\n",
    "    node_set= set(node_set)\n",
    "    article_index=list(article_set)\n",
    "    node_index=list(node_set)\n",
    "    td=np.zeros((len(g.nodes()), len(article_set)))\n",
    "    for nd,art in g.node(data='art_id'):\n",
    "        for art_s in art:\n",
    "            td[node_index.index(nd)][article_index.index(art_s)]=1\n",
    "                \n",
    "    #document centrality feature \n",
    "    ca,cn=document_centrality(td,20)\n",
    "    node_feature=pd.DataFrame({'node_index':node_index,'term_centrality':cn})\n",
    "    article_feature=pd.DataFrame({'article_index':article_index,'article_centrality_on_node':ca})\n",
    "    return node_feature,article_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_data(df,kl,nodes,g_train,g_test):\n",
    "    train_labels=[]\n",
    "    train_rows = list(nx.non_edges(g_train))\n",
    "    for edge in train_rows:\n",
    "        if g_test.has_edge(edge[0],edge[1]):\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            train_labels.append(0)\n",
    "    train_data = pd.DataFrame({'row_name':train_rows,'label':train_labels})\n",
    "    test_data = pd.DataFrame({'row_name':list(set(g_test.edges()))})\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_set(df,kl,g,feature_frame,t0,t1):\n",
    "    #node and article feature\n",
    "    node_feature,article_feature = node_and_article_feature(df,kl,g,t0,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/apnea-all,3.csv')\n",
    "key_list = pd.read_csv('dataset/apnea-distinct_keyword.csv')\n",
    "article_keywords = pd.read_csv('dataset/apnea-art_id,keyword,key_id,3.csv')\n",
    "sm_df=df[(df['art_year']<2020)]\n",
    "sm_df=keyword_split(sm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=1991\n",
    "t1=1992\n",
    "t2=1993\n",
    "nodes=nodes_intersection(sm_df,key_list,t0,t1,t2)\n",
    "g=nx.Graph()\n",
    "g_train=build_graph(g,sm_df,key_list,nodes,t0,t1)\n",
    "g=nx.Graph()\n",
    "g_test=build_graph(g,sm_df,key_list,nodes,t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 20 36 36 36\n"
     ]
    }
   ],
   "source": [
    "print(len(g_train.edges()),len(g_test.edges()),len(g_train.nodes()),len(g_test.nodes()),len(nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "599 11\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data=classification_data(sm_df,key_list,nodes,g_train,g_test)\n",
    "build_feature_set(sm_df,key_list,g_train,train_data,t0,t1)\n",
    "print(len(train_data),len(train_data[(train_data['label']==1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196350 / 325583\n"
     ]
    }
   ],
   "source": [
    "st=0\n",
    "end=330\n",
    "cut=4\n",
    "tds=train_data\n",
    "coun2=0\n",
    "coun=[]\n",
    "for i,j in tds.iterrows():\n",
    "    coun1=0\n",
    "    nb1=set(nx.neighbors(g_train,j[0][0]))\n",
    "    nb2=set(nx.neighbors(g_train,j[0][1]))\n",
    "    nb1h2=nb1.copy()\n",
    "    nb2h2=nb2.copy()\n",
    "    for n2b1 in nb1h2:\n",
    "        nb=set(nx.neighbors(g_train,n2b1))\n",
    "        nb1.update(nb)\n",
    "    for n2b2 in nb2h2:\n",
    "        nb=set(nx.neighbors(g_train,n2b2))\n",
    "        nb2.update(nb)    \n",
    "    for nnb1 in nb1:\n",
    "        for nnb2 in nb2:\n",
    "            if(nnb1==nnb2):\n",
    "                coun1=coun1+1\n",
    "    if coun1>0:\n",
    "        coun2=coun2+1\n",
    "    coun.append(coun1)  \n",
    "print(coun2,\"/\",len(tds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=0\n",
    "end=100000\n",
    "cut=4\n",
    "tds=train_data[(train_data['label']==0)]\n",
    "tds=tds[0:end]\n",
    "coun2=0\n",
    "for i,j in tds.iterrows():\n",
    "    coun1=0\n",
    "    nb1=set(nx.neighbors(g_train,j[0][0]))\n",
    "    nb2=set(nx.neighbors(g_train,j[0][1]))\n",
    "    nb1h2=nb1.copy()\n",
    "    nb2h2=nb2.copy()\n",
    "    for n2b1 in nb1h2:\n",
    "        nb=set(nx.neighbors(g_train,n2b1))\n",
    "        nb1.update(nb)\n",
    "    for n2b2 in nb2h2:\n",
    "        nb=set(nx.neighbors(g_train,n2b2))\n",
    "        nb2.update(nb)\n",
    "    for nnb in nb1:\n",
    "        nnb1=set(nx.neighbors(g_train,nnb))\n",
    "        for nnnb in nnb1:\n",
    "            nnnb1=set(nx.neighbors(g_train,nnnb))\n",
    "            if(j[0][1] in nnnb1):\n",
    "                coun1=coun1+1\n",
    "    if coun1>0:\n",
    "        coun2=coun2+1\n",
    "print(coun2,\"/\",len(tds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1666666666666665 ---- cut: 3 ----- avg: 8050.666666666667 ----------\n",
      "3.5757575757575757 ---- cut: 4 ----- avg: 102718.75 ----------\n"
     ]
    }
   ],
   "source": [
    "st=0\n",
    "end=330\n",
    "cut=5\n",
    "tds=train_data[(train_data['label']==1)]\n",
    "#tds=tds[0:end]\n",
    "for jj in range(3,cut):\n",
    "    count=0\n",
    "    total=0\n",
    "    for i,j in tds.iterrows():\n",
    "        paths = list( nx.all_simple_paths(g_train, source=j[0][0], target=j[0][1],cutoff=jj))\n",
    "        nb1=set(nx.neighbors(g_train,j[0][0]))\n",
    "        if len(paths)!=0:\n",
    "            #print(j[0][0],'+',j[0][1],\"----\",len(paths))\n",
    "            count=count+1\n",
    "            total=total+len(paths)\n",
    "    print(count,\"/\",end,\"----\",\"cut:\",jj,\"-----\",\"avg:\",total/(jj),\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5909090909090908 ---- cut: 3 ----- avg: 21.666666666666668 ----------\n"
     ]
    }
   ],
   "source": [
    "end=4*330\n",
    "tds=train_data[(train_data['label']==0)]\n",
    "tds=tds[3*330:end]\n",
    "for jj in range(3,cut):\n",
    "    count=0\n",
    "    total=0\n",
    "    for i,j in tds.iterrows():\n",
    "        paths = list( nx.all_simple_paths(g_train, source=j[0][0], target=j[0][1],cutoff=jj))\n",
    "        if len(paths)!=0:\n",
    "            #print(j[0][0],'+',j[0][1],\"----\",len(paths))\n",
    "            count=count+1\n",
    "            total=total+len(paths)\n",
    "    print(count/end,\"----\",\"cut:\",jj,\"-----\",\"avg:\",total/(jj),\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds=train_data[(train_data['label']==0)]\n",
    "cm_neigh_len=[]\n",
    "cm_neigh_list=[]\n",
    "for i,j in train_data.iterrows():\n",
    "    coun=0\n",
    "    cm = list(nx.common_neighbors(g_train, j[0][0],j[0][1]))\n",
    "    cm_neigh_len.append(len(cm))\n",
    "    cm_neigh_list.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cm']=cm_neigh_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=0\n",
    "end=10000\n",
    "cut=4\n",
    "tds=train_data[(train_data['label']==0)]\n",
    "#tds=tds[0:end]\n",
    "coun2=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discard_negative(train_data,g_train):\n",
    "    #pref attach\n",
    "    pref = nx.preferential_attachment(g_train,list(train_data['row_name']))\n",
    "    pref = list(pref)\n",
    "    train_data['pref']=np.array(pref)[:,2]\n",
    "    cm_neigh_len=[]\n",
    "    cm_neigh_list=[]\n",
    "    for i,j in train_data.iterrows():\n",
    "        coun=0\n",
    "        cm = list(nx.common_neighbors(g_train, j[0][0],j[0][1]))\n",
    "        cm_neigh_len.append(len(cm))\n",
    "        cm_neigh_list.append(cm)\n",
    "    train_data['cm']=cm_neigh_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref = nx.preferential_attachment(g_train,list(train_data['row_name']))\n",
    "pref = list(pref)\n",
    "train_data['pref']=np.array(pref)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_neigh_len=[]\n",
    "cm_neigh_list=[]\n",
    "for i,j in train_data.iterrows():\n",
    "    coun=0\n",
    "    cm = list(nx.common_neighbors(g_train, j[0][0],j[0][1]))\n",
    "    cm_neigh_len.append(len(cm))\n",
    "    cm_neigh_list.append(cm)\n",
    "train_data['cm']=cm_neigh_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cm_hop2']=coun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['soundara']=np.array(soundara)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6943 296\n"
     ]
    }
   ],
   "source": [
    "l1= len(train_data[((train_data['pref']>0)&(train_data['cm']>1)&(train_data['cm_hop2']>0))& (train_data['label']==0)])\n",
    "l2= len(train_data[((train_data['pref']>0)&(train_data['cm']>1)&(train_data['cm_hop2']>0))& (train_data['label']==1)])\n",
    "print(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[(train_data['cm_hop2']>0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_df['art_year'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osteotomy + surgery\n",
      "[10248, 10248]\n",
      "----------------------------------------------------\n",
      "osteotomy + distraction\n",
      "[10248, 10248]\n",
      "----------------------------------------------------\n",
      "osteotomy + maxilla\n",
      "[10248, 10248]\n",
      "----------------------------------------------------\n",
      "osteotomy + sleep\n",
      "[10248, 10248]\n",
      "----------------------------------------------------\n",
      "osteotomy + apert syndrome\n",
      "[10248, 10248]\n",
      "----------------------------------------------------\n",
      "osteotomy + obstructive\n",
      "[10248, 10248]\n",
      "----------------------------------------------------\n",
      "malocclusion + overjet\n",
      "[8202]\n",
      "----------------------------------------------------\n",
      "sleep position + children\n",
      "[14349, 14349, 14349, 14349, 14349]\n",
      "----------------------------------------------------\n",
      "sleep position + supine position\n",
      "[14349, 14349, 14349, 14349, 14349]\n",
      "----------------------------------------------------\n",
      "paediatric + morbid obesity\n",
      "[14348]\n",
      "----------------------------------------------------\n",
      "paediatric + anaesthesia\n",
      "[14348]\n",
      "----------------------------------------------------\n",
      "sleep apea syndrome + chiari malformation\n",
      "[12307, 12307]\n",
      "----------------------------------------------------\n",
      "sleep apea syndrome + behaviour\n",
      "[12307, 12307]\n",
      "----------------------------------------------------\n",
      "heated humidification + humidity\n",
      "[]\n",
      "----------------------------------------------------\n",
      "car accident + excessive daytime sleepiness\n",
      "[]\n",
      "----------------------------------------------------\n",
      "management + excessive daytime sleepiness\n",
      "[8211, 8211]\n",
      "----------------------------------------------------\n",
      "outcome + surgery\n",
      "[10266, 10266, 10266, 10266]\n",
      "----------------------------------------------------\n",
      "outcome + meta analysis\n",
      "[10266, 10266, 10266, 10266]\n",
      "----------------------------------------------------\n",
      "sleep structure + schizophrenia\n",
      "[16413]\n",
      "----------------------------------------------------\n",
      "sleep structure + depression\n",
      "[16413]\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,j in train_data[(train_data['label']==1)][0:20].iterrows():\n",
    "    print (node_label_find(key_list,j[0][0]),\"+\",node_label_find(key_list,j[0][1]))\n",
    "    t1=[]\n",
    "    t2=[]\n",
    "    for n1 in g_train[j[0][0]]:\n",
    "        t1.append(j[0][0])\n",
    "    for n2 in g_train[j[0][1]]:\n",
    "        t2.append(g_train[j[0][1]][n2]['title'])\n",
    "    print(t1)\n",
    "    print(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({5741: {'art_id': {106857}, 'year': {2001}, 'title': {'Mortised genioplasty in the treatment of obstructive sleep apnea An historical perspective and modification of design'}, 'weight': 1}, 13102: {'art_id': {106857}, 'year': {2001}, 'title': {'Mortised genioplasty in the treatment of obstructive sleep apnea An historical perspective and modification of design'}, 'weight': 1}})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_train[10248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-491fac12c5f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msm_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'art_year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sm_df' is not defined"
     ]
    }
   ],
   "source": [
    "sm_df.groupby('art_year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyemd' from 'C:\\\\Users\\\\faisal\\\\Anaconda3\\\\lib\\\\site-packages\\\\pyemd\\\\__init__.py'>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from pyemd import emd\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.matutils import softcossim\n",
    "import importlib\n",
    "importlib.reload(pyemd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('pubmed2018_w2v_200D/pubmed2018_w2v_200D.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_obama = 'hi world'.lower().split()\n",
    "sentence_president = 'hellow world'.lower().split()\n",
    "sentence_orange = 'congenital central hypoventilation syndrome'.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [sentence_obama, sentence_president, sentence_orange]\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(document) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sentences into bag-of-words vectors.\n",
    "sentence_obama = dictionary.doc2bow(sentence_obama)\n",
    "sentence_president = dictionary.doc2bow(sentence_president)\n",
    "sentence_orange = dictionary.doc2bow(sentence_orange)\n",
    "similarity_matrix = word_vectors.similarity_matrix(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softcossim() missing 1 required positional argument: 'similarity_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-73ebc188ff8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimilarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftcossim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_obama\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_president\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'similarity = %.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: softcossim() missing 1 required positional argument: 'similarity_matrix'"
     ]
    }
   ],
   "source": [
    "similarity = softcossim(sentence_obama, sentence_president, similarity_matrix)\n",
    "print('similarity = %.4f' % similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Please install pyemd Python package to compute WMD.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-7e88f3f575b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwmdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sleepiness'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'insomnia'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mwmdistance\u001b[1;34m(self, document1, document2)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPYEMD_EXT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please install pyemd Python package to compute WMD.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;31m# Remove out-of-vocabulary words.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Please install pyemd Python package to compute WMD."
     ]
    }
   ],
   "source": [
    "word_vectors.wmdistance('sleepiness', 'insomnia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755101093935269"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.n_similarity('sleepiness'.lower().split(), 'insomnia'.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-88d96843a926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-779d907b2a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-88d96843a926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Get some time series data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/timeseries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-03-18</td>\n",
       "      <td>24.68</td>\n",
       "      <td>164.93</td>\n",
       "      <td>114.73</td>\n",
       "      <td>26.27</td>\n",
       "      <td>19.21</td>\n",
       "      <td>28.87</td>\n",
       "      <td>63.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-03-19</td>\n",
       "      <td>24.18</td>\n",
       "      <td>164.89</td>\n",
       "      <td>114.75</td>\n",
       "      <td>26.22</td>\n",
       "      <td>19.07</td>\n",
       "      <td>27.76</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-03-20</td>\n",
       "      <td>23.99</td>\n",
       "      <td>164.63</td>\n",
       "      <td>115.04</td>\n",
       "      <td>25.78</td>\n",
       "      <td>19.01</td>\n",
       "      <td>27.04</td>\n",
       "      <td>59.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-03-25</td>\n",
       "      <td>24.14</td>\n",
       "      <td>163.92</td>\n",
       "      <td>114.85</td>\n",
       "      <td>27.41</td>\n",
       "      <td>19.61</td>\n",
       "      <td>27.84</td>\n",
       "      <td>59.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-03-26</td>\n",
       "      <td>24.44</td>\n",
       "      <td>163.45</td>\n",
       "      <td>114.84</td>\n",
       "      <td>26.86</td>\n",
       "      <td>19.53</td>\n",
       "      <td>28.02</td>\n",
       "      <td>60.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-03-27</td>\n",
       "      <td>24.38</td>\n",
       "      <td>163.46</td>\n",
       "      <td>115.40</td>\n",
       "      <td>27.09</td>\n",
       "      <td>19.72</td>\n",
       "      <td>28.25</td>\n",
       "      <td>59.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-03-28</td>\n",
       "      <td>24.32</td>\n",
       "      <td>163.22</td>\n",
       "      <td>115.56</td>\n",
       "      <td>27.13</td>\n",
       "      <td>19.63</td>\n",
       "      <td>28.24</td>\n",
       "      <td>58.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-03-31</td>\n",
       "      <td>24.19</td>\n",
       "      <td>164.02</td>\n",
       "      <td>115.54</td>\n",
       "      <td>26.74</td>\n",
       "      <td>19.55</td>\n",
       "      <td>28.43</td>\n",
       "      <td>59.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>23.81</td>\n",
       "      <td>163.59</td>\n",
       "      <td>115.72</td>\n",
       "      <td>27.82</td>\n",
       "      <td>20.21</td>\n",
       "      <td>29.17</td>\n",
       "      <td>56.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-04-02</td>\n",
       "      <td>24.03</td>\n",
       "      <td>163.32</td>\n",
       "      <td>115.11</td>\n",
       "      <td>28.22</td>\n",
       "      <td>20.42</td>\n",
       "      <td>29.38</td>\n",
       "      <td>56.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008-04-03</td>\n",
       "      <td>24.34</td>\n",
       "      <td>163.34</td>\n",
       "      <td>115.17</td>\n",
       "      <td>28.14</td>\n",
       "      <td>20.36</td>\n",
       "      <td>29.51</td>\n",
       "      <td>57.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date      A       B       C      D      E      F      G\n",
       "0   2008-03-18  24.68  164.93  114.73  26.27  19.21  28.87  63.44\n",
       "1   2008-03-19  24.18  164.89  114.75  26.22  19.07  27.76  59.98\n",
       "2   2008-03-20  23.99  164.63  115.04  25.78  19.01  27.04  59.61\n",
       "3   2008-03-25  24.14  163.92  114.85  27.41  19.61  27.84  59.41\n",
       "4   2008-03-26  24.44  163.45  114.84  26.86  19.53  28.02  60.09\n",
       "5   2008-03-27  24.38  163.46  115.40  27.09  19.72  28.25  59.62\n",
       "6   2008-03-28  24.32  163.22  115.56  27.13  19.63  28.24  58.65\n",
       "7   2008-03-31  24.19  164.02  115.54  26.74  19.55  28.43  59.20\n",
       "8   2008-04-01  23.81  163.59  115.72  27.82  20.21  29.17  56.18\n",
       "9   2008-04-02  24.03  163.32  115.11  28.22  20.42  29.38  56.64\n",
       "10  2008-04-03  24.34  163.34  115.17  28.14  20.36  29.51  57.49"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = [\"A\",\"B\"] \n",
    "df['single_input_vector'] = df[['B','C']].apply(tuple, axis=1).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['single_input_vector'] = df.single_input_vector.apply(lambda x: [list(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cumulative_input_vectors'] = df.single_input_vector.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols=['B','C']\n",
    "df['output_vector'] = df[output_cols].apply(tuple, axis=1).apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_sequence_length = df.cumulative_input_vectors.apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = pad_sequences(df.cumulative_input_vectors.tolist(), max_sequence_length).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['padded_input_vectors'] = pd.Series(padded_sequences).apply(np.asarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_init = np.asarray(df.padded_input_vectors)\n",
    "X_train = np.hstack(X_train_init).reshape(len(df),max_sequence_length,len(input_cols))\n",
    "y_train = np.hstack(np.asarray(df.output_vector)).reshape(len(df),len(output_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = X_train.shape[1]\n",
    "input_dim = X_train.shape[2]\n",
    "output_dim = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(input_length,input_dim)))\n",
    "# The max output value is > 1 so relu is used as final activation.\n",
    "model.add(Dense(output_dim, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 2 samples\n",
      "Epoch 1/170\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5050 - acc: 1.0000 - val_loss: 0.6746 - val_acc: 0.5000\n",
      "Epoch 2/170\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5038 - acc: 1.0000 - val_loss: 0.6734 - val_acc: 0.5000\n",
      "Epoch 3/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5026 - acc: 1.0000 - val_loss: 0.6724 - val_acc: 0.5000\n",
      "Epoch 4/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5015 - acc: 1.0000 - val_loss: 0.6716 - val_acc: 0.5000\n",
      "Epoch 5/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5005 - acc: 1.0000 - val_loss: 0.6707 - val_acc: 0.5000\n",
      "Epoch 6/170\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4995 - acc: 1.0000 - val_loss: 0.6698 - val_acc: 0.5000\n",
      "Epoch 7/170\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4985 - acc: 1.0000 - val_loss: 0.6689 - val_acc: 0.5000\n",
      "Epoch 8/170\n",
      "4/4 [==============================] - 0s 877us/step - loss: 0.4975 - acc: 1.0000 - val_loss: 0.6680 - val_acc: 0.5000\n",
      "Epoch 9/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4964 - acc: 1.0000 - val_loss: 0.6672 - val_acc: 0.5000\n",
      "Epoch 10/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4954 - acc: 1.0000 - val_loss: 0.6664 - val_acc: 0.5000\n",
      "Epoch 11/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4945 - acc: 1.0000 - val_loss: 0.6657 - val_acc: 0.5000\n",
      "Epoch 12/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4935 - acc: 1.0000 - val_loss: 0.6651 - val_acc: 0.5000\n",
      "Epoch 13/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4925 - acc: 1.0000 - val_loss: 0.6645 - val_acc: 0.5000\n",
      "Epoch 14/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4916 - acc: 1.0000 - val_loss: 0.6641 - val_acc: 0.5000\n",
      "Epoch 15/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4906 - acc: 1.0000 - val_loss: 0.6637 - val_acc: 0.5000\n",
      "Epoch 16/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4897 - acc: 1.0000 - val_loss: 0.6634 - val_acc: 0.5000\n",
      "Epoch 17/170\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.4888 - acc: 1.0000 - val_loss: 0.6632 - val_acc: 0.5000\n",
      "Epoch 18/170\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.4878 - acc: 1.0000 - val_loss: 0.6631 - val_acc: 0.5000\n",
      "Epoch 19/170\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4869 - acc: 1.0000 - val_loss: 0.6631 - val_acc: 0.5000\n",
      "Epoch 20/170\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.4859 - acc: 1.0000 - val_loss: 0.6632 - val_acc: 0.5000\n",
      "Epoch 21/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4850 - acc: 1.0000 - val_loss: 0.6634 - val_acc: 0.5000\n",
      "Epoch 22/170\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.4840 - acc: 1.0000 - val_loss: 0.6637 - val_acc: 0.5000\n",
      "Epoch 23/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4831 - acc: 1.0000 - val_loss: 0.6641 - val_acc: 0.5000\n",
      "Epoch 24/170\n",
      "4/4 [==============================] - 0s 607us/step - loss: 0.4821 - acc: 1.0000 - val_loss: 0.6645 - val_acc: 0.5000\n",
      "Epoch 25/170\n",
      "4/4 [==============================] - 0s 504us/step - loss: 0.4812 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.5000\n",
      "Epoch 26/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4802 - acc: 1.0000 - val_loss: 0.6655 - val_acc: 0.5000\n",
      "Epoch 27/170\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4793 - acc: 1.0000 - val_loss: 0.6661 - val_acc: 0.5000\n",
      "Epoch 28/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4783 - acc: 1.0000 - val_loss: 0.6667 - val_acc: 0.5000\n",
      "Epoch 29/170\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.4774 - acc: 1.0000 - val_loss: 0.6673 - val_acc: 0.5000\n",
      "Epoch 30/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4765 - acc: 1.0000 - val_loss: 0.6679 - val_acc: 0.5000\n",
      "Epoch 31/170\n",
      "4/4 [==============================] - 0s 756us/step - loss: 0.4755 - acc: 1.0000 - val_loss: 0.6686 - val_acc: 0.5000\n",
      "Epoch 32/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4746 - acc: 1.0000 - val_loss: 0.6693 - val_acc: 0.5000\n",
      "Epoch 33/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4737 - acc: 1.0000 - val_loss: 0.6700 - val_acc: 0.5000\n",
      "Epoch 34/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4728 - acc: 1.0000 - val_loss: 0.6707 - val_acc: 0.5000\n",
      "Epoch 35/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4719 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.5000\n",
      "Epoch 36/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4709 - acc: 1.0000 - val_loss: 0.6720 - val_acc: 0.5000\n",
      "Epoch 37/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4700 - acc: 1.0000 - val_loss: 0.6727 - val_acc: 0.5000\n",
      "Epoch 38/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4691 - acc: 1.0000 - val_loss: 0.6733 - val_acc: 0.5000\n",
      "Epoch 39/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4683 - acc: 1.0000 - val_loss: 0.6739 - val_acc: 0.5000\n",
      "Epoch 40/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4674 - acc: 1.0000 - val_loss: 0.6744 - val_acc: 0.5000\n",
      "Epoch 41/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4664 - acc: 1.0000 - val_loss: 0.6750 - val_acc: 0.5000\n",
      "Epoch 42/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4656 - acc: 1.0000 - val_loss: 0.6755 - val_acc: 0.5000\n",
      "Epoch 43/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4647 - acc: 1.0000 - val_loss: 0.6759 - val_acc: 0.5000\n",
      "Epoch 44/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4638 - acc: 1.0000 - val_loss: 0.6764 - val_acc: 0.5000\n",
      "Epoch 45/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4629 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.5000\n",
      "Epoch 46/170\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4620 - acc: 1.0000 - val_loss: 0.6772 - val_acc: 0.5000\n",
      "Epoch 47/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4612 - acc: 1.0000 - val_loss: 0.6776 - val_acc: 0.5000\n",
      "Epoch 48/170\n",
      "4/4 [==============================] - 0s 627us/step - loss: 0.4603 - acc: 1.0000 - val_loss: 0.6779 - val_acc: 0.5000\n",
      "Epoch 49/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4594 - acc: 1.0000 - val_loss: 0.6783 - val_acc: 0.5000\n",
      "Epoch 50/170\n",
      "4/4 [==============================] - 0s 879us/step - loss: 0.4585 - acc: 1.0000 - val_loss: 0.6787 - val_acc: 0.5000\n",
      "Epoch 51/170\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.4576 - acc: 1.0000 - val_loss: 0.6791 - val_acc: 0.5000\n",
      "Epoch 52/170\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4569 - acc: 1.0000 - val_loss: 0.6796 - val_acc: 0.5000\n",
      "Epoch 53/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4562 - acc: 1.0000 - val_loss: 0.6803 - val_acc: 0.5000\n",
      "Epoch 54/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4554 - acc: 1.0000 - val_loss: 0.6810 - val_acc: 0.5000\n",
      "Epoch 55/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4545 - acc: 1.0000 - val_loss: 0.6819 - val_acc: 0.5000\n",
      "Epoch 56/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4536 - acc: 1.0000 - val_loss: 0.6828 - val_acc: 0.5000\n",
      "Epoch 57/170\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4527 - acc: 1.0000 - val_loss: 0.6837 - val_acc: 0.5000\n",
      "Epoch 58/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4519 - acc: 1.0000 - val_loss: 0.6845 - val_acc: 0.5000\n",
      "Epoch 59/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4511 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 0.5000\n",
      "Epoch 60/170\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.4503 - acc: 1.0000 - val_loss: 0.6859 - val_acc: 0.5000\n",
      "Epoch 61/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4495 - acc: 1.0000 - val_loss: 0.6865 - val_acc: 0.5000\n",
      "Epoch 62/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4487 - acc: 1.0000 - val_loss: 0.6871 - val_acc: 0.5000\n",
      "Epoch 63/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4479 - acc: 1.0000 - val_loss: 0.6876 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/170\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.4471 - acc: 1.0000 - val_loss: 0.6881 - val_acc: 0.5000\n",
      "Epoch 65/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4463 - acc: 1.0000 - val_loss: 0.6885 - val_acc: 0.5000\n",
      "Epoch 66/170\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4454 - acc: 1.0000 - val_loss: 0.6889 - val_acc: 0.5000\n",
      "Epoch 67/170\n",
      "4/4 [==============================] - 0s 627us/step - loss: 0.4446 - acc: 1.0000 - val_loss: 0.6892 - val_acc: 0.5000\n",
      "Epoch 68/170\n",
      "4/4 [==============================] - 0s 627us/step - loss: 0.4437 - acc: 1.0000 - val_loss: 0.6896 - val_acc: 0.5000\n",
      "Epoch 69/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4430 - acc: 1.0000 - val_loss: 0.6900 - val_acc: 0.5000\n",
      "Epoch 70/170\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.4422 - acc: 1.0000 - val_loss: 0.6906 - val_acc: 0.5000\n",
      "Epoch 71/170\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.4413 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 0.5000\n",
      "Epoch 72/170\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.4405 - acc: 1.0000 - val_loss: 0.6919 - val_acc: 0.5000\n",
      "Epoch 73/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4397 - acc: 1.0000 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 74/170\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.4389 - acc: 1.0000 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 75/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4380 - acc: 1.0000 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 76/170\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.4372 - acc: 1.0000 - val_loss: 0.6938 - val_acc: 0.5000\n",
      "Epoch 77/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4363 - acc: 1.0000 - val_loss: 0.6942 - val_acc: 0.5000\n",
      "Epoch 78/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4355 - acc: 1.0000 - val_loss: 0.6945 - val_acc: 0.5000\n",
      "Epoch 79/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4347 - acc: 1.0000 - val_loss: 0.6949 - val_acc: 0.5000\n",
      "Epoch 80/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4338 - acc: 1.0000 - val_loss: 0.6955 - val_acc: 0.5000\n",
      "Epoch 81/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4330 - acc: 1.0000 - val_loss: 0.6960 - val_acc: 0.5000\n",
      "Epoch 82/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4321 - acc: 1.0000 - val_loss: 0.6964 - val_acc: 0.5000\n",
      "Epoch 83/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4313 - acc: 1.0000 - val_loss: 0.6968 - val_acc: 0.5000\n",
      "Epoch 84/170\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.4304 - acc: 1.0000 - val_loss: 0.6971 - val_acc: 0.5000\n",
      "Epoch 85/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4295 - acc: 1.0000 - val_loss: 0.6974 - val_acc: 0.5000\n",
      "Epoch 86/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4287 - acc: 1.0000 - val_loss: 0.6978 - val_acc: 0.5000\n",
      "Epoch 87/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4278 - acc: 1.0000 - val_loss: 0.6983 - val_acc: 0.5000\n",
      "Epoch 88/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4269 - acc: 1.0000 - val_loss: 0.6987 - val_acc: 0.5000\n",
      "Epoch 89/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4260 - acc: 1.0000 - val_loss: 0.6991 - val_acc: 0.5000\n",
      "Epoch 90/170\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.4252 - acc: 1.0000 - val_loss: 0.6994 - val_acc: 0.5000\n",
      "Epoch 91/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4243 - acc: 1.0000 - val_loss: 0.6997 - val_acc: 0.5000\n",
      "Epoch 92/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4234 - acc: 1.0000 - val_loss: 0.6999 - val_acc: 0.5000\n",
      "Epoch 93/170\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.4224 - acc: 1.0000 - val_loss: 0.7001 - val_acc: 0.5000\n",
      "Epoch 94/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4216 - acc: 1.0000 - val_loss: 0.7004 - val_acc: 0.5000\n",
      "Epoch 95/170\n",
      "4/4 [==============================] - 0s 877us/step - loss: 0.4208 - acc: 1.0000 - val_loss: 0.7007 - val_acc: 0.5000\n",
      "Epoch 96/170\n",
      "4/4 [==============================] - 0s 628us/step - loss: 0.4200 - acc: 1.0000 - val_loss: 0.7009 - val_acc: 0.5000\n",
      "Epoch 97/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4191 - acc: 1.0000 - val_loss: 0.7011 - val_acc: 0.5000\n",
      "Epoch 98/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4183 - acc: 1.0000 - val_loss: 0.7012 - val_acc: 0.5000\n",
      "Epoch 99/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4174 - acc: 1.0000 - val_loss: 0.7012 - val_acc: 0.5000\n",
      "Epoch 100/170\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4165 - acc: 1.0000 - val_loss: 0.7012 - val_acc: 0.5000\n",
      "Epoch 101/170\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.4156 - acc: 1.0000 - val_loss: 0.7013 - val_acc: 0.5000\n",
      "Epoch 102/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4147 - acc: 1.0000 - val_loss: 0.7015 - val_acc: 0.5000\n",
      "Epoch 103/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4138 - acc: 1.0000 - val_loss: 0.7016 - val_acc: 0.5000\n",
      "Epoch 104/170\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4130 - acc: 1.0000 - val_loss: 0.7017 - val_acc: 0.5000\n",
      "Epoch 105/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4121 - acc: 1.0000 - val_loss: 0.7018 - val_acc: 0.5000\n",
      "Epoch 106/170\n",
      "4/4 [==============================] - 0s 844us/step - loss: 0.4112 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.5000\n",
      "Epoch 107/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4103 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.5000\n",
      "Epoch 108/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4094 - acc: 1.0000 - val_loss: 0.7020 - val_acc: 0.5000\n",
      "Epoch 109/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4085 - acc: 1.0000 - val_loss: 0.7022 - val_acc: 0.5000\n",
      "Epoch 110/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4076 - acc: 1.0000 - val_loss: 0.7022 - val_acc: 0.5000\n",
      "Epoch 111/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4067 - acc: 1.0000 - val_loss: 0.7025 - val_acc: 0.5000\n",
      "Epoch 112/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4058 - acc: 1.0000 - val_loss: 0.7026 - val_acc: 0.5000\n",
      "Epoch 113/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4049 - acc: 1.0000 - val_loss: 0.7026 - val_acc: 0.5000\n",
      "Epoch 114/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4040 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.5000\n",
      "Epoch 115/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.4031 - acc: 1.0000 - val_loss: 0.7028 - val_acc: 0.5000\n",
      "Epoch 116/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4021 - acc: 1.0000 - val_loss: 0.7029 - val_acc: 0.5000\n",
      "Epoch 117/170\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.4012 - acc: 1.0000 - val_loss: 0.7031 - val_acc: 0.5000\n",
      "Epoch 118/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4003 - acc: 1.0000 - val_loss: 0.7033 - val_acc: 0.5000\n",
      "Epoch 119/170\n",
      "4/4 [==============================] - 0s 879us/step - loss: 0.3994 - acc: 1.0000 - val_loss: 0.7034 - val_acc: 0.5000\n",
      "Epoch 120/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3985 - acc: 1.0000 - val_loss: 0.7035 - val_acc: 0.5000\n",
      "Epoch 121/170\n",
      "4/4 [==============================] - 0s 877us/step - loss: 0.3975 - acc: 1.0000 - val_loss: 0.7035 - val_acc: 0.5000\n",
      "Epoch 122/170\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.3966 - acc: 1.0000 - val_loss: 0.7035 - val_acc: 0.5000\n",
      "Epoch 123/170\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.3956 - acc: 1.0000 - val_loss: 0.7036 - val_acc: 0.5000\n",
      "Epoch 124/170\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.3947 - acc: 1.0000 - val_loss: 0.7036 - val_acc: 0.5000\n",
      "Epoch 125/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3938 - acc: 1.0000 - val_loss: 0.7038 - val_acc: 0.5000\n",
      "Epoch 126/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 752us/step - loss: 0.3928 - acc: 1.0000 - val_loss: 0.7040 - val_acc: 0.5000\n",
      "Epoch 127/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3919 - acc: 1.0000 - val_loss: 0.7041 - val_acc: 0.5000\n",
      "Epoch 128/170\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.3909 - acc: 1.0000 - val_loss: 0.7042 - val_acc: 0.5000\n",
      "Epoch 129/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3899 - acc: 1.0000 - val_loss: 0.7042 - val_acc: 0.5000\n",
      "Epoch 130/170\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.3890 - acc: 1.0000 - val_loss: 0.7043 - val_acc: 0.5000\n",
      "Epoch 131/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3880 - acc: 1.0000 - val_loss: 0.7043 - val_acc: 0.5000\n",
      "Epoch 132/170\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3871 - acc: 1.0000 - val_loss: 0.7043 - val_acc: 0.5000\n",
      "Epoch 133/170\n",
      "4/4 [==============================] - 0s 626us/step - loss: 0.3861 - acc: 1.0000 - val_loss: 0.7044 - val_acc: 0.5000\n",
      "Epoch 134/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3852 - acc: 1.0000 - val_loss: 0.7047 - val_acc: 0.5000\n",
      "Epoch 135/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3842 - acc: 1.0000 - val_loss: 0.7048 - val_acc: 0.5000\n",
      "Epoch 136/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3832 - acc: 1.0000 - val_loss: 0.7049 - val_acc: 0.5000\n",
      "Epoch 137/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3823 - acc: 1.0000 - val_loss: 0.7049 - val_acc: 0.5000\n",
      "Epoch 138/170\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3813 - acc: 1.0000 - val_loss: 0.7049 - val_acc: 0.5000\n",
      "Epoch 139/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3803 - acc: 1.0000 - val_loss: 0.7048 - val_acc: 0.5000\n",
      "Epoch 140/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3793 - acc: 1.0000 - val_loss: 0.7047 - val_acc: 0.5000\n",
      "Epoch 141/170\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3784 - acc: 1.0000 - val_loss: 0.7048 - val_acc: 0.5000\n",
      "Epoch 142/170\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.3775 - acc: 1.0000 - val_loss: 0.7051 - val_acc: 0.5000\n",
      "Epoch 143/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3765 - acc: 1.0000 - val_loss: 0.7053 - val_acc: 0.5000\n",
      "Epoch 144/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3756 - acc: 1.0000 - val_loss: 0.7054 - val_acc: 0.5000\n",
      "Epoch 145/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3747 - acc: 1.0000 - val_loss: 0.7055 - val_acc: 0.5000\n",
      "Epoch 146/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3738 - acc: 1.0000 - val_loss: 0.7056 - val_acc: 0.5000\n",
      "Epoch 147/170\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.3729 - acc: 1.0000 - val_loss: 0.7058 - val_acc: 0.5000\n",
      "Epoch 148/170\n",
      "4/4 [==============================] - 0s 626us/step - loss: 0.3720 - acc: 1.0000 - val_loss: 0.7062 - val_acc: 0.5000\n",
      "Epoch 149/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3711 - acc: 1.0000 - val_loss: 0.7064 - val_acc: 0.5000\n",
      "Epoch 150/170\n",
      "4/4 [==============================] - 0s 377us/step - loss: 0.3702 - acc: 1.0000 - val_loss: 0.7066 - val_acc: 0.5000\n",
      "Epoch 151/170\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.3692 - acc: 1.0000 - val_loss: 0.7067 - val_acc: 0.5000\n",
      "Epoch 152/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3683 - acc: 1.0000 - val_loss: 0.7068 - val_acc: 0.5000\n",
      "Epoch 153/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3674 - acc: 1.0000 - val_loss: 0.7069 - val_acc: 0.5000\n",
      "Epoch 154/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3665 - acc: 1.0000 - val_loss: 0.7071 - val_acc: 0.5000\n",
      "Epoch 155/170\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.3655 - acc: 1.0000 - val_loss: 0.7074 - val_acc: 0.5000\n",
      "Epoch 156/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3646 - acc: 1.0000 - val_loss: 0.7077 - val_acc: 0.5000\n",
      "Epoch 157/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3637 - acc: 1.0000 - val_loss: 0.7079 - val_acc: 0.5000\n",
      "Epoch 158/170\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3628 - acc: 1.0000 - val_loss: 0.7080 - val_acc: 0.5000\n",
      "Epoch 159/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3618 - acc: 1.0000 - val_loss: 0.7081 - val_acc: 0.5000\n",
      "Epoch 160/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3608 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.5000\n",
      "Epoch 161/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3598 - acc: 1.0000 - val_loss: 0.7086 - val_acc: 0.5000\n",
      "Epoch 162/170\n",
      "4/4 [==============================] - 0s 627us/step - loss: 0.3589 - acc: 1.0000 - val_loss: 0.7090 - val_acc: 0.5000\n",
      "Epoch 163/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3579 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.5000\n",
      "Epoch 164/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3569 - acc: 1.0000 - val_loss: 0.7097 - val_acc: 0.5000\n",
      "Epoch 165/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3559 - acc: 1.0000 - val_loss: 0.7100 - val_acc: 0.5000\n",
      "Epoch 166/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3549 - acc: 1.0000 - val_loss: 0.7102 - val_acc: 0.5000\n",
      "Epoch 167/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3540 - acc: 1.0000 - val_loss: 0.7105 - val_acc: 0.5000\n",
      "Epoch 168/170\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3530 - acc: 1.0000 - val_loss: 0.7109 - val_acc: 0.5000\n",
      "Epoch 169/170\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3519 - acc: 1.0000 - val_loss: 0.7113 - val_acc: 0.5000\n",
      "Epoch 170/170\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3510 - acc: 1.0000 - val_loss: 0.7116 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "#Set batch_size to 7 to show that it doesn't have to be a factor or multiple of your sample size\n",
    "history = model.fit(X_train, y_train,validation_split=0.3, shuffle=True,\n",
    "              batch_size=7, epochs=170,\n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[163.71799 , 115.03436 ],\n",
       "       [163.71896 , 115.03505 ],\n",
       "       [163.71928 , 115.03526 ],\n",
       "       [163.71939 , 115.03534 ],\n",
       "       [163.71942 , 115.03537 ],\n",
       "       [163.71944 , 115.03538 ],\n",
       "       [163.71944 , 115.03538 ],\n",
       "       [163.71945 , 115.035385],\n",
       "       [163.71945 , 115.035385],\n",
       "       [163.71945 , 115.035385],\n",
       "       [163.71945 , 115.035385]], dtype=float32)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[164.93, 114.73],\n",
       "       [164.89, 114.75],\n",
       "       [164.63, 115.04],\n",
       "       [163.92, 114.85],\n",
       "       [163.45, 114.84],\n",
       "       [163.46, 115.4 ],\n",
       "       [163.22, 115.56],\n",
       "       [164.02, 115.54],\n",
       "       [163.59, 115.72],\n",
       "       [163.32, 115.11],\n",
       "       [163.34, 115.17]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([\n",
    "\t[\n",
    "\t\t[\n",
    "\t\t\t1,3,4,1\n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t3,2,1,2\n",
    "\t\t]\n",
    "\t],\n",
    "\t[\n",
    "\t\t[\n",
    "\t\t\t4,1,5,4\n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t6,7,2,1\n",
    "\t\t]\n",
    "\t],\n",
    "\t[\n",
    "\t\t[\n",
    "\t\t\t5,8,1,7\n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t9,1,8,4\n",
    "\t\t]\n",
    "\t],\n",
    "    [\n",
    "\t\t[\n",
    "\t\t\t2,3,4,1\n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t5,2,1,2\n",
    "\t\t]\n",
    "\t],\n",
    "\t[\n",
    "\t\t[\n",
    "\t\t\t4,1,5,4\n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t6,7,2,1\n",
    "\t\t]\n",
    "\t],\n",
    "\t[\n",
    "\t\t[\n",
    "\t\t\t9,8,1,7\n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t1,1,2,4\n",
    "\t\t]\n",
    "\t]\n",
    "])\n",
    "\n",
    "y=np.array([0,0,0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0, random_state = 0)\n",
    "input_length = X_train.shape[1]\n",
    "input_dim = X_train.shape[2]\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(input_length,input_dim)))\n",
    "# The max output value is > 1 so relu is used as final activation.\n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2 samples, validate on 2 samples\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5555 - acc: 1.0000 - val_loss: 0.7462 - val_acc: 0.5000\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5539 - acc: 1.0000 - val_loss: 0.7452 - val_acc: 0.5000\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5523 - acc: 1.0000 - val_loss: 0.7442 - val_acc: 0.5000\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5507 - acc: 1.0000 - val_loss: 0.7431 - val_acc: 0.5000\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5491 - acc: 1.0000 - val_loss: 0.7420 - val_acc: 0.5000\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5476 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.5000\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5461 - acc: 1.0000 - val_loss: 0.7399 - val_acc: 0.5000\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5446 - acc: 1.0000 - val_loss: 0.7388 - val_acc: 0.5000\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5432 - acc: 1.0000 - val_loss: 0.7377 - val_acc: 0.5000\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5417 - acc: 1.0000 - val_loss: 0.7366 - val_acc: 0.5000\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5402 - acc: 1.0000 - val_loss: 0.7355 - val_acc: 0.5000\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5388 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.5000\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5373 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.5000\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5359 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.5000\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5345 - acc: 1.0000 - val_loss: 0.7310 - val_acc: 0.5000\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5330 - acc: 1.0000 - val_loss: 0.7299 - val_acc: 0.5000\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5316 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 0.5000\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5302 - acc: 1.0000 - val_loss: 0.7275 - val_acc: 0.5000\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5288 - acc: 1.0000 - val_loss: 0.7263 - val_acc: 0.5000\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5274 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 0.5000\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5260 - acc: 1.0000 - val_loss: 0.7238 - val_acc: 0.5000\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5246 - acc: 1.0000 - val_loss: 0.7225 - val_acc: 0.5000\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5232 - acc: 1.0000 - val_loss: 0.7212 - val_acc: 0.5000\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5218 - acc: 1.0000 - val_loss: 0.7199 - val_acc: 0.5000\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5204 - acc: 1.0000 - val_loss: 0.7186 - val_acc: 0.5000\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5190 - acc: 1.0000 - val_loss: 0.7172 - val_acc: 0.5000\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5176 - acc: 1.0000 - val_loss: 0.7159 - val_acc: 0.5000\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5163 - acc: 1.0000 - val_loss: 0.7147 - val_acc: 0.5000\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5149 - acc: 1.0000 - val_loss: 0.7133 - val_acc: 0.5000\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5136 - acc: 1.0000 - val_loss: 0.7121 - val_acc: 0.5000\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5124 - acc: 1.0000 - val_loss: 0.7109 - val_acc: 0.5000\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5111 - acc: 1.0000 - val_loss: 0.7096 - val_acc: 0.5000\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5098 - acc: 1.0000 - val_loss: 0.7084 - val_acc: 0.5000\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5085 - acc: 1.0000 - val_loss: 0.7072 - val_acc: 0.5000\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5072 - acc: 1.0000 - val_loss: 0.7061 - val_acc: 0.5000\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5059 - acc: 1.0000 - val_loss: 0.7049 - val_acc: 0.5000\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5046 - acc: 1.0000 - val_loss: 0.7037 - val_acc: 0.5000\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5033 - acc: 1.0000 - val_loss: 0.7026 - val_acc: 0.5000\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5019 - acc: 1.0000 - val_loss: 0.7014 - val_acc: 0.5000\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5006 - acc: 1.0000 - val_loss: 0.7003 - val_acc: 0.5000\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4993 - acc: 1.0000 - val_loss: 0.6993 - val_acc: 0.5000\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4980 - acc: 1.0000 - val_loss: 0.6983 - val_acc: 0.5000\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4968 - acc: 1.0000 - val_loss: 0.6973 - val_acc: 0.5000\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4955 - acc: 1.0000 - val_loss: 0.6963 - val_acc: 0.5000\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4942 - acc: 1.0000 - val_loss: 0.6953 - val_acc: 0.5000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4930 - acc: 1.0000 - val_loss: 0.6943 - val_acc: 0.5000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4917 - acc: 1.0000 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4904 - acc: 1.0000 - val_loss: 0.6924 - val_acc: 0.5000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4892 - acc: 1.0000 - val_loss: 0.6914 - val_acc: 0.5000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4879 - acc: 1.0000 - val_loss: 0.6905 - val_acc: 0.5000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4866 - acc: 1.0000 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4853 - acc: 1.0000 - val_loss: 0.6886 - val_acc: 0.5000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4841 - acc: 1.0000 - val_loss: 0.6877 - val_acc: 0.5000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4828 - acc: 1.0000 - val_loss: 0.6868 - val_acc: 0.5000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4815 - acc: 1.0000 - val_loss: 0.6860 - val_acc: 0.5000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4803 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 0.5000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4791 - acc: 1.0000 - val_loss: 0.6844 - val_acc: 0.5000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4779 - acc: 1.0000 - val_loss: 0.6836 - val_acc: 0.5000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4766 - acc: 1.0000 - val_loss: 0.6829 - val_acc: 0.5000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4754 - acc: 1.0000 - val_loss: 0.6821 - val_acc: 0.5000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4741 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.5000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4729 - acc: 1.0000 - val_loss: 0.6808 - val_acc: 0.5000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4717 - acc: 1.0000 - val_loss: 0.6801 - val_acc: 0.5000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4704 - acc: 1.0000 - val_loss: 0.6794 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4692 - acc: 1.0000 - val_loss: 0.6788 - val_acc: 0.5000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4680 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 0.5000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4667 - acc: 1.0000 - val_loss: 0.6774 - val_acc: 0.5000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4655 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.5000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4642 - acc: 1.0000 - val_loss: 0.6762 - val_acc: 0.5000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4630 - acc: 1.0000 - val_loss: 0.6756 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,validation_split=0.3,\n",
    "              batch_size=7, epochs=70,\n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5806007 ],\n",
       "       [0.42457026]], dtype=float32)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "col_names = [\"aa\",\"bb\", \"cc\", \"dd\"]\n",
    "all_combinations = itertools.chain(*[itertools.combinations(col_names,i+1) for i,_ in enumerate(col_names)])\n",
    "ff= list(all_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa']\n",
      "['bb']\n",
      "['cc']\n",
      "['dd']\n",
      "['aa', 'bb']\n",
      "['aa', 'cc']\n",
      "['aa', 'dd']\n",
      "['bb', 'cc']\n",
      "['bb', 'dd']\n",
      "['cc', 'dd']\n",
      "['aa', 'bb', 'cc']\n",
      "['aa', 'bb', 'dd']\n",
      "['aa', 'cc', 'dd']\n",
      "['bb', 'cc', 'dd']\n",
      "['aa', 'bb', 'cc', 'dd']\n"
     ]
    }
   ],
   "source": [
    "for i in ff:\n",
    "    print(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-365-6c38563ac2b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1991\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "t = train_data[1991].columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = 5 * np.random.randn(100) + 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_list = pd.read_csv(\"dataset\\obesity keyword to clean.csv\")\n",
    "new_list = pd.read_csv(\"dataset\\ob09-11toclean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_keyword</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knee society score</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Protein Kinase A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pancreatic Cancer</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microbiology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minimally Invasive Surgery</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  old_keyword  count\n",
       "0          knee society score      3\n",
       "1            Protein Kinase A      2\n",
       "2           Pancreatic Cancer     32\n",
       "3                microbiology      2\n",
       "4  Minimally Invasive Surgery     25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(old_list, new_list, on='old_keyword', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_keyword</th>\n",
       "      <th>new_keyword</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 fructose solution</td>\n",
       "      <td>10 fructose solution</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-beta hydroxysteroid dehydrogenase 1</td>\n",
       "      <td>11-beta hydroxysteroid dehydrogenase 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11b-hsd type 1</td>\n",
       "      <td>11-beta hydroxysteroid dehydrogenase 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-hsd</td>\n",
       "      <td>11-beta hydroxysteroid dehydrogenase 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              old_keyword  \\\n",
       "0                                       1   \n",
       "1                    10 fructose solution   \n",
       "2  11-beta hydroxysteroid dehydrogenase 1   \n",
       "3                          11b-hsd type 1   \n",
       "4                                  11-hsd   \n",
       "\n",
       "                              new_keyword  count  \n",
       "0                                       1   10.0  \n",
       "1                    10 fructose solution    NaN  \n",
       "2  11-beta hydroxysteroid dehydrogenase 1    NaN  \n",
       "3  11-beta hydroxysteroid dehydrogenase 1    NaN  \n",
       "4  11-beta hydroxysteroid dehydrogenase 1    NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_keyword</th>\n",
       "      <th>new_keyword</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 fructose solution</td>\n",
       "      <td>10 fructose solution</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-beta hydroxysteroid dehydrogenase 1</td>\n",
       "      <td>11-beta hydroxysteroid dehydrogenase 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11b-hsd type 1</td>\n",
       "      <td>11-beta hydroxysteroid dehydrogenase 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-hsd</td>\n",
       "      <td>11-beta hydroxysteroid dehydrogenase 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11hsd1</td>\n",
       "      <td>11-hydroxysteroid dehydrogenase type 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11-hsd1</td>\n",
       "      <td>11-hydroxysteroid dehydrogenase type 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11-hsd1 inhibition</td>\n",
       "      <td>11-hydroxysteroid dehydrogenase inhibitor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11-hsd1 inhibitor</td>\n",
       "      <td>11-hydroxysteroid dehydrogenase inhibitor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11-hydroxysteroid</td>\n",
       "      <td>11-hydroxysteroid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11-hydroxysteroid dehydrogenase</td>\n",
       "      <td>11-hydroxysteroid dehydrogenase</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12-dimethylbenzaanthracene</td>\n",
       "      <td>12-dimethylbenzaanthracene</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14-3-3</td>\n",
       "      <td>14-3-3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16s rrna</td>\n",
       "      <td>16s rrna</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17-alpha hydroxyprogesterone caproate</td>\n",
       "      <td>17-alpha hydroxyprogesterone caproate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18fdg-craving-zucker-food restriction</td>\n",
       "      <td>18fdg-craving-zucker-food restriction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18f-fdg</td>\n",
       "      <td>fluorodeoxyglucose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18-glycyrrhetinic acid</td>\n",
       "      <td>18-glycyrrhetinic acid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1996 world food summit</td>\n",
       "      <td>1996 world food summit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1-deoxynojirimycin</td>\n",
       "      <td>1-deoxynojirimycin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1gf-1</td>\n",
       "      <td>1gf-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1h-quino7</td>\n",
       "      <td>1h-quino7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1rm</td>\n",
       "      <td>1rm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2010 dietary guidelines for americans</td>\n",
       "      <td>2010 dietary guidelines for americans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015 dietary guidelines</td>\n",
       "      <td>2015 dietary guidelines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>22 countries</td>\n",
       "      <td>22 countries</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>24 h energy expenditure</td>\n",
       "      <td>24-h energy expenditure</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>24-h ph-metry</td>\n",
       "      <td>24-h ph-metry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24-hour dietary recall</td>\n",
       "      <td>24-hour dietary recall</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>25d</td>\n",
       "      <td>25d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25-hydroxivitamin d3</td>\n",
       "      <td>25-hydroxivitamin d3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12899</th>\n",
       "      <td>young women</td>\n",
       "      <td>young women</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12900</th>\n",
       "      <td>youngia denticulata</td>\n",
       "      <td>youngia denticulata</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12901</th>\n",
       "      <td>youth</td>\n",
       "      <td>youth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>youth aged 10-14 years</td>\n",
       "      <td>youth aged 10-14 years</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>youth development</td>\n",
       "      <td>youth development</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12904</th>\n",
       "      <td>youth obesity</td>\n",
       "      <td>youth obesity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12905</th>\n",
       "      <td>youth or adolescents</td>\n",
       "      <td>youth or adolescent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12906</th>\n",
       "      <td>youth self-report questionnaire</td>\n",
       "      <td>youth self-report questionnaire</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12907</th>\n",
       "      <td>youth/adolescence</td>\n",
       "      <td>youth/adolescence</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12908</th>\n",
       "      <td>youth/emergent adulthood</td>\n",
       "      <td>youth/emergent adulthood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12909</th>\n",
       "      <td>zag</td>\n",
       "      <td>zinc-alpha2-glycoprotein</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12910</th>\n",
       "      <td>zdf rats</td>\n",
       "      <td>zucker diabetic fatty rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12911</th>\n",
       "      <td>zebrafish</td>\n",
       "      <td>zebrafish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12912</th>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>zimbabwe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12913</th>\n",
       "      <td>zinc</td>\n",
       "      <td>zinc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12914</th>\n",
       "      <td>zinc deficiency</td>\n",
       "      <td>zinc deficiency</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12915</th>\n",
       "      <td>zinc supplementation</td>\n",
       "      <td>zinc supplementation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12916</th>\n",
       "      <td>zinc-alpha2-glycoprotein</td>\n",
       "      <td>zinc-alpha2-glycoprotein</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12917</th>\n",
       "      <td>zingiber officinale</td>\n",
       "      <td>zingiber officinale</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12918</th>\n",
       "      <td>zip code</td>\n",
       "      <td>zip code</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12921</th>\n",
       "      <td>zp</td>\n",
       "      <td>zp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12922</th>\n",
       "      <td>z-score hyperandrogenism</td>\n",
       "      <td>z-score hyperandrogenism</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12923</th>\n",
       "      <td>zucker</td>\n",
       "      <td>zucker</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12924</th>\n",
       "      <td>zucker diabetes fatty rat</td>\n",
       "      <td>zucker diabetic fatty rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12925</th>\n",
       "      <td>zucker diabetic fatty</td>\n",
       "      <td>zucker diabetic fatty</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12926</th>\n",
       "      <td>zucker diabetic fatty rat</td>\n",
       "      <td>zucker diabetic fatty rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12927</th>\n",
       "      <td>zucker fa/fa rat</td>\n",
       "      <td>zucker diabetic fatty rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12928</th>\n",
       "      <td>zucker rat</td>\n",
       "      <td>zucker diabetic fatty rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12929</th>\n",
       "      <td>zucker rats</td>\n",
       "      <td>zucker diabetic fatty rat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12930</th>\n",
       "      <td>zumba</td>\n",
       "      <td>zumba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11762 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  old_keyword  \\\n",
       "1                        10 fructose solution   \n",
       "2      11-beta hydroxysteroid dehydrogenase 1   \n",
       "3                              11b-hsd type 1   \n",
       "4                                      11-hsd   \n",
       "5                                      11hsd1   \n",
       "6                                     11-hsd1   \n",
       "7                          11-hsd1 inhibition   \n",
       "8                           11-hsd1 inhibitor   \n",
       "9                           11-hydroxysteroid   \n",
       "10            11-hydroxysteroid dehydrogenase   \n",
       "13                 12-dimethylbenzaanthracene   \n",
       "14                                     14-3-3   \n",
       "15                                   16s rrna   \n",
       "16      17-alpha hydroxyprogesterone caproate   \n",
       "18      18fdg-craving-zucker-food restriction   \n",
       "19                                    18f-fdg   \n",
       "20                     18-glycyrrhetinic acid   \n",
       "21                     1996 world food summit   \n",
       "22                         1-deoxynojirimycin   \n",
       "23                                      1gf-1   \n",
       "24                                  1h-quino7   \n",
       "25                                        1rm   \n",
       "27      2010 dietary guidelines for americans   \n",
       "28                    2015 dietary guidelines   \n",
       "29                               22 countries   \n",
       "30                    24 h energy expenditure   \n",
       "32                              24-h ph-metry   \n",
       "33                     24-hour dietary recall   \n",
       "34                                        25d   \n",
       "35                       25-hydroxivitamin d3   \n",
       "...                                       ...   \n",
       "12899                             young women   \n",
       "12900                     youngia denticulata   \n",
       "12901                                   youth   \n",
       "12902                  youth aged 10-14 years   \n",
       "12903                       youth development   \n",
       "12904                           youth obesity   \n",
       "12905                    youth or adolescents   \n",
       "12906         youth self-report questionnaire   \n",
       "12907                       youth/adolescence   \n",
       "12908                youth/emergent adulthood   \n",
       "12909                                     zag   \n",
       "12910                                zdf rats   \n",
       "12911                               zebrafish   \n",
       "12912                                zimbabwe   \n",
       "12913                                    zinc   \n",
       "12914                         zinc deficiency   \n",
       "12915                    zinc supplementation   \n",
       "12916                zinc-alpha2-glycoprotein   \n",
       "12917                     zingiber officinale   \n",
       "12918                                zip code   \n",
       "12921                                      zp   \n",
       "12922                z-score hyperandrogenism   \n",
       "12923                                  zucker   \n",
       "12924               zucker diabetes fatty rat   \n",
       "12925                   zucker diabetic fatty   \n",
       "12926               zucker diabetic fatty rat   \n",
       "12927                        zucker fa/fa rat   \n",
       "12928                              zucker rat   \n",
       "12929                             zucker rats   \n",
       "12930                                   zumba   \n",
       "\n",
       "                                     new_keyword  count  \n",
       "1                           10 fructose solution    NaN  \n",
       "2         11-beta hydroxysteroid dehydrogenase 1    NaN  \n",
       "3         11-beta hydroxysteroid dehydrogenase 1    NaN  \n",
       "4         11-beta hydroxysteroid dehydrogenase 1    NaN  \n",
       "5         11-hydroxysteroid dehydrogenase type 1    NaN  \n",
       "6         11-hydroxysteroid dehydrogenase type 1    NaN  \n",
       "7      11-hydroxysteroid dehydrogenase inhibitor    NaN  \n",
       "8      11-hydroxysteroid dehydrogenase inhibitor    NaN  \n",
       "9                              11-hydroxysteroid    NaN  \n",
       "10               11-hydroxysteroid dehydrogenase    NaN  \n",
       "13                    12-dimethylbenzaanthracene    NaN  \n",
       "14                                        14-3-3    NaN  \n",
       "15                                      16s rrna    NaN  \n",
       "16         17-alpha hydroxyprogesterone caproate    NaN  \n",
       "18         18fdg-craving-zucker-food restriction    NaN  \n",
       "19                            fluorodeoxyglucose    NaN  \n",
       "20                        18-glycyrrhetinic acid    NaN  \n",
       "21                        1996 world food summit    NaN  \n",
       "22                            1-deoxynojirimycin    NaN  \n",
       "23                                         1gf-1    NaN  \n",
       "24                                     1h-quino7    NaN  \n",
       "25                                           1rm    NaN  \n",
       "27         2010 dietary guidelines for americans    NaN  \n",
       "28                       2015 dietary guidelines    NaN  \n",
       "29                                  22 countries    NaN  \n",
       "30                       24-h energy expenditure    NaN  \n",
       "32                                 24-h ph-metry    NaN  \n",
       "33                        24-hour dietary recall    NaN  \n",
       "34                                           25d    NaN  \n",
       "35                          25-hydroxivitamin d3    NaN  \n",
       "...                                          ...    ...  \n",
       "12899                                young women    NaN  \n",
       "12900                        youngia denticulata    NaN  \n",
       "12901                                      youth    NaN  \n",
       "12902                     youth aged 10-14 years    NaN  \n",
       "12903                          youth development    NaN  \n",
       "12904                              youth obesity    NaN  \n",
       "12905                        youth or adolescent    NaN  \n",
       "12906            youth self-report questionnaire    NaN  \n",
       "12907                          youth/adolescence    NaN  \n",
       "12908                   youth/emergent adulthood    NaN  \n",
       "12909                   zinc-alpha2-glycoprotein    NaN  \n",
       "12910                  zucker diabetic fatty rat    NaN  \n",
       "12911                                  zebrafish    NaN  \n",
       "12912                                   zimbabwe    NaN  \n",
       "12913                                       zinc    NaN  \n",
       "12914                            zinc deficiency    NaN  \n",
       "12915                       zinc supplementation    NaN  \n",
       "12916                   zinc-alpha2-glycoprotein    NaN  \n",
       "12917                        zingiber officinale    NaN  \n",
       "12918                                   zip code    NaN  \n",
       "12921                                         zp    NaN  \n",
       "12922                   z-score hyperandrogenism    NaN  \n",
       "12923                                     zucker    NaN  \n",
       "12924                  zucker diabetic fatty rat    NaN  \n",
       "12925                      zucker diabetic fatty    NaN  \n",
       "12926                  zucker diabetic fatty rat    NaN  \n",
       "12927                  zucker diabetic fatty rat    NaN  \n",
       "12928                  zucker diabetic fatty rat    NaN  \n",
       "12929                  zucker diabetic fatty rat    NaN  \n",
       "12930                                      zumba    NaN  \n",
       "\n",
       "[11762 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[merged['count'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
